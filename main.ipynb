{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process ama announcement data\n",
    "import json\n",
    "\n",
    "data = json.load(open(\"./json/ama.json\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "# convert json to csv\n",
    "with open('./csv/ama.csv', 'w') as f:\n",
    "    # headers: id, content, timestamp,  author.id, author.username, attachments url as a string list\n",
    "    headers = ['id', 'content', 'timestamp', 'author_id', 'author_username', 'attachments']\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        writer.writerow({\n",
    "            'id': item['id'],\n",
    "            'content': item['content'],\n",
    "            'timestamp': item['timestamp'],\n",
    "            'author_id': item['author']['id'],\n",
    "            'author_username': item['author']['username'],\n",
    "            'attachments': ','.join([x['url'] for x in item['attachments']])\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# process community announcement data\n",
    "import json\n",
    "\n",
    "data = json.load(open(\"./json/community.json\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "# convert json to csv\n",
    "with open('./csv/offcial.csv', 'w') as f:\n",
    "    # headers: id, content, timestamp,  author.id, author.username, attachments url as a string list\n",
    "    headers = ['id', 'content', 'timestamp', 'author_id', 'author_username', 'attachments']\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        writer.writerow({\n",
    "            'id': item['id'],\n",
    "            'content': item['content'],\n",
    "            'timestamp': item['timestamp'],\n",
    "            'author_id': item['author']['id'],\n",
    "            'author_username': item['author']['username'],\n",
    "            'attachments': ','.join([x['url'] for x in item['attachments']])\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process official announcement data\n",
    "import json\n",
    "\n",
    "data = json.load(open(\"./json/official.json\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "# convert json to csv\n",
    "with open('./csv/community.csv', 'w') as f:\n",
    "    # headers: id, content, timestamp,  author.id, author.username, attachments url as a string list\n",
    "    headers = ['id', 'content', 'timestamp', 'author_id', 'author_username', 'attachments']\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        writer.writerow({\n",
    "            'id': item['id'],\n",
    "            'content': item['content'],\n",
    "            'timestamp': item['timestamp'],\n",
    "            'author_id': item['author']['id'],\n",
    "            'author_username': item['author']['username'],\n",
    "            'attachments': ','.join([x['url'] for x in item['attachments']])\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process phbc announcement data\n",
    "import json\n",
    "\n",
    "data = json.load(open(\"./json/phbc.json\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "# convert json to csv\n",
    "with open('./csv/phbc.csv', 'w') as f:\n",
    "    # headers: id, content, timestamp,  author.id, author.username, attachments url as a string list\n",
    "    headers = ['id', 'content', 'timestamp', 'author_id', 'author_username', 'attachments']\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for item in data:\n",
    "        writer.writerow({\n",
    "            'id': item['id'],\n",
    "            'content': item['content'],\n",
    "            'timestamp': item['timestamp'],\n",
    "            'author_id': item['author']['id'],\n",
    "            'author_username': item['author']['username'],\n",
    "            'attachments': ','.join([x['url'] for x in item['attachments']])\n",
    "        })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# process socials announcement data\n",
    "import json\n",
    "\n",
    "data = json.load(open(\"./json/socials.json\"))\n",
    "\n",
    "import csv\n",
    "\n",
    "# convert json to csv\n",
    "with open(\"./csv/socials.csv\", \"w\") as f:\n",
    "    # headers: id, content, timestamp,  author.id, author.username, attachments url as a string list\n",
    "    headers = [\n",
    "        \"id\",\n",
    "        \"content\",\n",
    "        \"timestamp\",\n",
    "        \"author_id\",\n",
    "        \"author_username\",\n",
    "        \"attachments\",\n",
    "        \"embed_1_url\",\n",
    "        \"embed_1_desc\",\n",
    "        \"embed_1_images\",\n",
    "        \"embed_2_url\",\n",
    "        \"embed_2_desc\",\n",
    "        \"embed_2_images\",\n",
    "    ]\n",
    "\n",
    "    writer = csv.DictWriter(f, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "\n",
    "    embed_1_url = \"\"\n",
    "    embed_1_desc = \"\"\n",
    "    embed_1_images = \"\"\n",
    "    embed_2_url = \"\"\n",
    "    embed_2_desc = \"\"\n",
    "    embed_2_images = \"\"\n",
    "\n",
    "    for item in data:\n",
    "        # group embeds based on url\n",
    "        embeds = {}\n",
    "        for embed in item[\"embeds\"]:\n",
    "            # if url field does not exist\n",
    "            if \"url\" not in embed:\n",
    "                # create url as empty string\n",
    "                embed[\"url\"] = \"\"\n",
    "            if embed[\"url\"] not in embeds:\n",
    "                embeds[embed[\"url\"]] = []\n",
    "            # create image field if it does not exist\n",
    "            if \"image\" not in embed:\n",
    "                embed[\"image\"] = {}\n",
    "                embed[\"image\"][\"url\"] = \"\"\n",
    "            embeds[embed[\"url\"]].append(embed)\n",
    "        # print(embeds)\n",
    "        key_list = list(embeds.keys())\n",
    "        print(len(key_list))\n",
    "        # iterate through key_list\n",
    "        for i in range(len(key_list)):\n",
    "            key_name = key_list[i]\n",
    "            # if i == 0\n",
    "            if i == 0:\n",
    "                embed_1_url = key_name\n",
    "                embed_1_desc = embeds[key_name][0][\"description\"]\n",
    "                embed_1_images = \",\".join([x[\"image\"][\"url\"] for x in embeds[key_name]])\n",
    "\n",
    "            if i == 1:\n",
    "                embed_2_url = key_name\n",
    "                embed_2_desc = embeds[key_name][0][\"description\"]\n",
    "                embed_2_images = \",\".join([x[\"image\"][\"url\"] for x in embeds[key_name]])\n",
    "\n",
    "        writer.writerow(\n",
    "            {\n",
    "                \"id\": item[\"id\"],\n",
    "                \"content\": item[\"content\"],\n",
    "                \"timestamp\": item[\"timestamp\"],\n",
    "                \"author_id\": item[\"author\"][\"id\"],\n",
    "                \"author_username\": item[\"author\"][\"username\"],\n",
    "                \"attachments\": \",\".join([x[\"url\"] for x in item[\"attachments\"]]),\n",
    "                \"embed_1_url\": embed_1_url,\n",
    "                \"embed_1_desc\": embed_1_desc,\n",
    "                \"embed_1_images\": embed_1_images,\n",
    "                \"embed_2_url\": embed_2_url,\n",
    "                \"embed_2_desc\": embed_2_desc,\n",
    "                \"embed_2_images\": embed_2_images,\n",
    "            }\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
